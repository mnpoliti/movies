{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c9a74e-d4f1-4df3-8304-fa7131ce98d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mpoli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mpoli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7770b9d6-c5cd-493f-9333-e0568b284403",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data = pd.read_csv(\"/Users/mpoli/Desktop/MASTER/DIPLOMATIKI/course_venv/API/API_csvs/tmdb_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54927a89-bad4-48b0-8f71-0839827d471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'budget', 'homepage', 'id', 'imdb_id', 'revenue',\n",
       "       'runtime', 'language', 'description', 'popularity', 'title', 'rating',\n",
       "       'votes', 'year', 'genre1', 'genre2', 'genre3', 'genre4', 'genre5',\n",
       "       'genre6', 'genre7', 'genre8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75009a27-88ff-4923-ad40-7984a79f0b29",
   "metadata": {},
   "source": [
    "##### first we will merge the columns with the genres in order to apply the new column in the tf-idf method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e45fc4b-f33f-464a-b5ef-13760c565151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  Action, Adventure, ScienceFiction\n",
       "1                    Action, Comedy, Crime, Thriller\n",
       "2                         Adventure, Family, Fantasy\n",
       "3         Action, Adventure, Fantasy, ScienceFiction\n",
       "4                         Action, Adventure, Fantasy\n",
       "                            ...                     \n",
       "9867                          Drama, Family, Romance\n",
       "9868                         Crime, Horror, Thriller\n",
       "9869        Drama, Mystery, ScienceFiction, Thriller\n",
       "9870                  Comedy, Horror, ScienceFiction\n",
       "9871    Adventure, Animation, Crime, Family, Mystery\n",
       "Name: genres, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data.fillna('empty', inplace=True)\n",
    "tf_data[\"genres\"] = (\n",
    "    tf_data[['genre1', 'genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8']]\n",
    "        .apply(lambda x: x.str.split(',\\s*'))\n",
    "        .sum(axis=1).map(np.array)\n",
    "        .apply(lambda x: ', '.join(np.unique(x[x != 'empty'])))        \n",
    "        .replace('', 'empty')\n",
    "    )\n",
    "tf_data.genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dab713-7e7c-4fa1-852e-1fa692db1ecf",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Because this is a multi-label classification problem we will treat thie as a Binary Relevance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4962b7-cfe0-4c0c-9ad0-4552a66c733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(tf_data['genres'])\n",
    "\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(tf_data['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b744857-7497-458c-85f4-dba30930bc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9872"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6a7b2e-cf3c-453c-8ee5-f7c636ae0240",
   "metadata": {},
   "source": [
    "##### description column transform into string type from object type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff9572f-e245-4e1b-9cb3-a3099caa4728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       int64\n",
       "budget           int64\n",
       "homepage        object\n",
       "id               int64\n",
       "imdb_id         object\n",
       "revenue          int64\n",
       "runtime          int64\n",
       "language        object\n",
       "description     string\n",
       "popularity     float64\n",
       "title           object\n",
       "rating         float64\n",
       "votes            int64\n",
       "year             int64\n",
       "genre1          object\n",
       "genre2          object\n",
       "genre3          object\n",
       "genre4          object\n",
       "genre5          object\n",
       "genre6          object\n",
       "genre7          object\n",
       "genre8          object\n",
       "genres          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data['description'] = tf_data['description'].astype(\"string\")\n",
    "tf_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39b2c2-1c59-43a9-b85c-25eb21414d22",
   "metadata": {},
   "source": [
    "#### Preproccesing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e1b28-1ecf-4014-9070-2af14ff323af",
   "metadata": {},
   "source": [
    "##### lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846778c2-8bd8-4f86-9140-996b9305d033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Set more than a decade after the events of the...\n",
       "1       When a team of mercenaries breaks into a wealt...\n",
       "2       Siblings Lucy, Edmund, Susan and Peter step th...\n",
       "3       In the 22nd century, a paraplegic Marine is di...\n",
       "4       Deep inside the mountain of Dovre, something g...\n",
       "                              ...                        \n",
       "9867    Louisa May Alcott's autobiographical account o...\n",
       "9868    After a serial killer strangles several women ...\n",
       "9869    At the dawn of the space-race, two radio-obses...\n",
       "9870    In the town of Dillford, humans, vampires and ...\n",
       "9871    A mysterious attacker has appeared and is assa...\n",
       "Name: description, Length: 9872, dtype: string"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657dc8f9-0901-4a61-b641-b6d90ce7a022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       set more than a decade after the events of the...\n",
       "1       when a team of mercenaries breaks into a wealt...\n",
       "2       siblings lucy, edmund, susan and peter step th...\n",
       "3       in the 22nd century, a paraplegic marine is di...\n",
       "4       deep inside the mountain of dovre, something g...\n",
       "                              ...                        \n",
       "9867    louisa may alcott's autobiographical account o...\n",
       "9868    after a serial killer strangles several women ...\n",
       "9869    at the dawn of the space-race, two radio-obses...\n",
       "9870    in the town of dillford, humans, vampires and ...\n",
       "9871    a mysterious attacker has appeared and is assa...\n",
       "Name: description, Length: 9872, dtype: string"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data['description'] = tf_data['description'].str.lower()\n",
    "tf_data.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a8a35-94ca-4703-9b95-f8c2f5a726c1",
   "metadata": {},
   "source": [
    "##### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2cc3e1d-afbd-4c64-805f-3992f4ba8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the libraries\n",
    "#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fffbc76e-f833-4566-bf32-4bd71bd77129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9286064-24de-4db7-b9e6-bf74041f4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8093be06-a0ec-49f8-989e-3bbec0e725c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       set decade events first film, learn story sull...\n",
       "1       team mercenaries breaks wealthy family compoun...\n",
       "2       siblings lucy, edmund, susan peter step magica...\n",
       "3       22nd century, paraplegic marine dispatched moo...\n",
       "4       deep inside mountain dovre, something gigantic...\n",
       "                              ...                        \n",
       "9867    louisa may alcott's autobiographical account l...\n",
       "9868    serial killer strangles several women necktie,...\n",
       "9869    dawn space-race, two radio-obsessed teens disc...\n",
       "9870    town dillford, humans, vampires zombies living...\n",
       "9871    mysterious attacker appeared assaulting people...\n",
       "Name: description, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe\n",
    "tf_data['description'] = tf_data['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "tf_data.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3040bc2-8823-4af3-8880-3f1ac27202c2",
   "metadata": {},
   "source": [
    "##### punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "074f3a5b-2dcb-40d9-a7bc-89f4721d259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#το κομμα να το βγάλω?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09fd5a48-5bae-493d-9f4a-ae4005dad5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mpoli\\AppData\\Local\\Temp\\ipykernel_10340\\420607143.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  tf_data.description = tf_data.description.str.replace(i,\" \")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       set decade events first film, learn story sull...\n",
       "1       team mercenaries breaks wealthy family compoun...\n",
       "2       siblings lucy, edmund, susan peter step magica...\n",
       "3       22nd century, paraplegic marine dispatched moo...\n",
       "4       deep inside mountain dovre, something gigantic...\n",
       "                              ...                        \n",
       "9867    louisa may alcott's autobiographical account l...\n",
       "9868    serial killer strangles several women necktie,...\n",
       "9869    dawn space race, two radio obsessed teens disc...\n",
       "9870    town dillford, humans, vampires zombies living...\n",
       "9871    mysterious attacker appeared assaulting people...\n",
       "Name: description, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n—”“–\"\n",
    "for i in symbols:\n",
    "    tf_data.description = tf_data.description.str.replace(i,\" \")\n",
    "tf_data.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f195c528-2fa6-476e-be2f-6b3669d92c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data.to_csv('tf_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af124a6-11db-4367-81e6-61e6c1be83b0",
   "metadata": {},
   "source": [
    "##### apostrophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "609067ba-36a0-41f0-8efa-d5dee9a4a27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       set decade events first film learn story sully...\n",
       "1       team mercenaries breaks wealthy family compoun...\n",
       "2       siblings lucy edmund susan peter step magical ...\n",
       "3       22nd century paraplegic marine dispatched moon...\n",
       "4       deep inside mountain dovre something gigantic ...\n",
       "                              ...                        \n",
       "9867    louisa may alcott s autobiographical account l...\n",
       "9868    serial killer strangles several women necktie ...\n",
       "9869    dawn space race two radio obsessed teens disco...\n",
       "9870    town dillford humans vampires zombies living p...\n",
       "9871    mysterious attacker appeared assaulting people...\n",
       "Name: description, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data.description = tf_data.description.str.replace(\"’\",\" \")\n",
    "tf_data.description = tf_data.description.str.replace(\"‘\",\" \")\n",
    "tf_data.description = tf_data.description.str.replace(\"'\",\" \")\n",
    "tf_data.description = tf_data.description.str.replace(\",\",\"\")\n",
    "tf_data.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edcf2a2-4384-4c63-8a33-8015cc56e769",
   "metadata": {},
   "source": [
    "##### stopwords again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7db40c3-9dc3-4426-b7d0-4c1271d1c771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       set decade events first film learn story sully...\n",
       "1       team mercenaries breaks wealthy family compoun...\n",
       "2       siblings lucy edmund susan peter step magical ...\n",
       "3       22nd century paraplegic marine dispatched moon...\n",
       "4       deep inside mountain dovre something gigantic ...\n",
       "                              ...                        \n",
       "9867    louisa may alcott autobiographical account lif...\n",
       "9868    serial killer strangles several women necktie ...\n",
       "9869    dawn space race two radio obsessed teens disco...\n",
       "9870    town dillford humans vampires zombies living p...\n",
       "9871    mysterious attacker appeared assaulting people...\n",
       "Name: description, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tf_data['description'] = tf_data['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "tf_data.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b5c4c-c292-4cae-a09f-5a942b9b5bc0",
   "metadata": {},
   "source": [
    "##### single characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06d88fed-4637-4bc8-ba6b-e96a841791ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       set decade events first film learn story sully...\n",
       "1       team mercenaries breaks wealthy family compoun...\n",
       "2       siblings lucy edmund susan peter step magical ...\n",
       "3       22nd century paraplegic marine dispatched moon...\n",
       "4       deep inside mountain dovre something gigantic ...\n",
       "                              ...                        \n",
       "9867    louisa may alcott autobiographical account lif...\n",
       "9868    serial killer strangles several women necktie ...\n",
       "9869    dawn space race two radio obsessed teens disco...\n",
       "9870    town dillford humans vampires zombies living p...\n",
       "9871    mysterious attacker appeared assaulting people...\n",
       "Name: description, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_data['description'] = tf_data['description'].apply(lambda x: ' '.join([word for word in x.split() if len(word) >1]))\n",
    "tf_data.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc927455-2e54-4057-bce9-7cdceda172c4",
   "metadata": {},
   "source": [
    "##### convert numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a636d8-82e5-4eee-9cac-d5d01ed1db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c62609d2-0dec-4c79-a413-163405c5481c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       set decade events first film learn story sully...\n",
       "1       team mercenaries breaks wealthy family compoun...\n",
       "2       siblings lucy edmund susan peter step magical ...\n",
       "3       22nd century paraplegic marine dispatched moon...\n",
       "4       deep inside mountain dovre something gigantic ...\n",
       "                              ...                        \n",
       "9867    louisa may alcott autobiographical account lif...\n",
       "9868    serial killer strangles several women necktie ...\n",
       "9869    dawn space race two radio obsessed teens disco...\n",
       "9870    town dillford humans vampires zombies living p...\n",
       "9871    mysterious attacker appeared assaulting people...\n",
       "Name: description, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/56733012/converting-number-in-sentences-to-word-in-python \n",
    "#is the for exaple 11th etc a problem?\n",
    "tf_data['description'] = tf_data['description'].apply(lambda x: ' '.join([num2words.num2words(i) if i.isdigit() else i for i in x.split()]))\n",
    "tf_data['description'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b30b251-ec7e-465d-ba42-c00076e7e4fc",
   "metadata": {},
   "source": [
    "##### punctuation and stopwords again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "200900b4-63cc-4ea5-816a-9bcd3519de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mpoli\\AppData\\Local\\Temp\\ipykernel_10340\\420607143.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  tf_data.description = tf_data.description.str.replace(i,\" \")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       set decade events first film learn story sully...\n",
       "1       team mercenaries breaks wealthy family compoun...\n",
       "2       siblings lucy edmund susan peter step magical ...\n",
       "3       22nd century paraplegic marine dispatched moon...\n",
       "4       deep inside mountain dovre something gigantic ...\n",
       "                              ...                        \n",
       "9867    louisa may alcott autobiographical account lif...\n",
       "9868    serial killer strangles several women necktie ...\n",
       "9869    dawn space race two radio obsessed teens disco...\n",
       "9870    town dillford humans vampires zombies living p...\n",
       "9871    mysterious attacker appeared assaulting people...\n",
       "Name: description, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n—”“–\"\n",
    "for i in symbols:\n",
    "    tf_data.description = tf_data.description.str.replace(i,\" \")\n",
    "tf_data.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdb5f482-d796-4bee-943c-92d71e4b10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data['description'] = tf_data['description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6e095-9d7e-4d33-9c94-68f50b1af5eb",
   "metadata": {},
   "source": [
    "##### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50598f41-db19-4bf3-b8f5-3384a3112d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58a1aa9d-59c7-4cfc-a5eb-1e5f903d2117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       set decad event first film learn stori sulli f...\n",
       "1       team mercenari break wealthi famili compound c...\n",
       "2       sibl luci edmund susan peter step magic wardro...\n",
       "3       22nd centuri parapleg marin dispatch moon pand...\n",
       "4       deep insid mountain dovr someth gigant awaken ...\n",
       "                              ...                        \n",
       "9867    louisa may alcott autobiograph account life th...\n",
       "9868    serial killer strangl sever women neckti londo...\n",
       "9869    dawn space race two radio obsess teen discov s...\n",
       "9870    town dillford human vampir zombi live peac ali...\n",
       "9871    mysteri attack appear assault peopl whose name...\n",
       "Name: description, Length: 9872, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##with Porter Stemmer\n",
    "#https://stackoverflow.com/questions/37443138/python-stemming-with-pandas-dataframe\n",
    "#https://www.projectpro.io/recipes/use-porter-stemmer\n",
    "ps = PorterStemmer()\n",
    "tf_data['description'] = tf_data['description'].apply(lambda x: ' '.join([ps.stem(y) for y in x.split()]))\n",
    "tf_data.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9818219-7bcf-4761-9b01-c7e68ef04d52",
   "metadata": {},
   "source": [
    "#### Apply TF-IDF to extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac70d113-e328-4527-a205-a85c655d3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4933485e-624d-41cf-9657-f23329a76e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?TfidfVectorizer\n",
    "#?train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6943c91-f80f-4b8b-8cdb-8e5e3ba4a12c",
   "metadata": {},
   "source": [
    "##### apply the algorithm of tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be5840a1-aad0-40a7-b5ff-f7745f220b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6910, 16991)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://medium.com/@kunalgupta4595/predicting-movie-genres-based-on-plot-summaries-bae646e70e04\n",
    "X= tf_data['description']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                   test_size = 0.3,\n",
    "                                   random_state = 42)\n",
    "\n",
    "tfidf = TfidfVectorizer() #ngram_range=(2,3)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) \n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "labels = tf_data.genres\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a42a383-e4f1-4ce4-a832-d5284fd65985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each of 4958 descriptions is represented by 13711 features, \n",
    "#representing the tf-idf score for different unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad498ba7-0c78-46d3-a032-68d6978482c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f\n",
    "#edo isos na kano auto me genres se numbers alla ola mazi se ena? ksexorista kai meta ola mazi?\n",
    "\n",
    "#from sklearn.feature_selection import chi2\n",
    "#import numpy as np\n",
    "#N = 2\n",
    "#for description, genres in sorted(tf_data.genres.items()):\n",
    "#  features_chi2 = chi2(X_train_tfidf, labels == genres)\n",
    "# indices = np.argsort(features_chi2[0])\n",
    "# feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "# bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "# trigrams = [v for v in feature_names if len(v.split(' ')) == 3]\n",
    "# print(\"# '{}':\".format(description))\n",
    "# print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "# print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(trigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d23a7-50a3-49c9-b437-ba873fc0c4bb",
   "metadata": {},
   "source": [
    "##### apply MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "471806b3-f1e1-47d1-8200-24257aaf784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f1aea3a-8b1b-4635-9e1f-c93f7258791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://slogix.in/source-code/python/deep-learning-samples/how-to-build-spam-detector-using-multi-layer-perceptron-in-python/\n",
    "clf = MLPClassifier(activation='relu',\n",
    "                    solver='adam',\n",
    "                    max_iter=200,\n",
    "                    hidden_layer_sizes=100,\n",
    "                    random_state=42,\n",
    "                    learning_rate='constant',\n",
    "                    learning_rate_init=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18689372-42bd-489f-b6ee-e37d347f1efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "y_pred[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f62286-4119-47cd-ac2b-9c6954f49466",
   "metadata": {},
   "source": [
    "##### inverse_transform( ) function along with the MultiLabelBinarizer( ) object to convert the predicted arrays into movie genre tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4bb17725-bda5-479e-95cd-6cf819b17543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407368737030318"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19ba00-df39-41e3-917f-ec1b992af907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get a decent F1 score of 0.7407368737030318. \n",
    "#These predictions were made based on a threshold value of 0.5, \n",
    "#which means that the probabilities greater than or equal to 0.5 were converted to 1’s and the rest to 0’s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7509c78-f3e7-4ff8-ab09-1f48794426de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s try to change this threshold value and see if that improves our model’s score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a718f438-84ef-4774-92c7-a89ef66bd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "y_pred_prob = clf.predict_proba(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcbb6702-9edd-4b86-962e-d30653ae1d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7476846565679632"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0.3 # threshold value\n",
    "y_pred_new = (y_pred_prob >= t).astype(int)\n",
    "f1_score(y_test, y_pred_new, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7931de74-9997-49f1-ac08-7800edbcf4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      2492\n",
      "           1       0.86      0.91      0.89      2492\n",
      "           2       0.73      0.66      0.69      1239\n",
      "           3       0.63      0.60      0.61      1232\n",
      "           4       0.60      0.56      0.58      1255\n",
      "           5       0.70      0.62      0.65       967\n",
      "           6       0.57      0.43      0.49       544\n",
      "           7       0.41      0.24      0.30       394\n",
      "           8       0.59      0.45      0.51       470\n",
      "           9       0.70      0.45      0.55       368\n",
      "          10       0.48      0.45      0.47       788\n",
      "          11       0.25      0.02      0.03        60\n",
      "          12       0.78      0.36      0.49       131\n",
      "          13       0.78      0.80      0.79      2039\n",
      "          14       0.66      0.68      0.67      1516\n",
      "          15       0.64      0.59      0.62      1313\n",
      "          16       0.86      0.92      0.89      2504\n",
      "          17       0.48      0.45      0.47       738\n",
      "          18       0.79      0.82      0.80      2036\n",
      "          19       0.54      0.54      0.54      1142\n",
      "          20       0.86      0.89      0.88      2384\n",
      "          21       0.75      0.80      0.78      1906\n",
      "          22       0.85      0.91      0.88      2449\n",
      "          23       0.00      0.00      0.00        19\n",
      "          24       0.84      0.90      0.87      2366\n",
      "          25       0.49      0.43      0.46       871\n",
      "          26       0.76      0.79      0.77      1795\n",
      "          27       0.55      0.41      0.47       706\n",
      "          28       0.53      0.36      0.43       617\n",
      "          29       0.70      0.70      0.70      1696\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     38529\n",
      "   macro avg       0.64      0.59      0.60     38529\n",
      "weighted avg       0.73      0.74      0.73     38529\n",
      " samples avg       0.75      0.75      0.72     38529\n",
      "\n",
      "Accuracy of the model :  2.2282241728561782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Classification report\\n\",metrics.classification_report(y_test, y_pred))\n",
    "print(\"Accuracy of the model : \",metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cee22-8b49-4dc9-9caa-dac6d581a95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10755f7-7c8c-4d75-8b6a-633437b0f236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
